{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d568b72-1b5d-44c8-aa1e-af8f3df7bec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset de empleados leído desde el archivo CSV:\n",
      "   ID_Empleado  Nombre Departamento  Salario Fecha_Ingreso\n",
      "0            1     Ana       Ventas    50000    2015-06-01\n",
      "1            2    Luis           TI    70000    2017-03-15\n",
      "2            3   Pedro    Marketing    60000    2018-11-01\n",
      "3            4   Marta           TI    75000    2020-01-10\n",
      "4            5  Carlos       Ventas    52000    2016-05-01\n",
      "5            6   Laura    Marketing    59000    2019-07-23\n",
      "6            7    José       Ventas    48000    2021-01-01\n",
      "\n",
      "Dataset de bonificaciones leído desde el archivo CSV:\n",
      "   ID_Empleado  Bonificacion\n",
      "0            1          5000\n",
      "1            2          8000\n",
      "2            3          3000\n",
      "3            4         10000\n",
      "4            5          2500\n",
      "5            6          4000\n",
      "6            7          1500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. Leer el archivo CSV de empleados\n",
    "ruta_archivo_empleados = 'C:/Users/layla/Escritorio/Fundamentos de ETL con Python/Codigos y Notebooks/14. Transformaciones Avanzadas/empleados.csv'\n",
    "df_empleados = pd.read_csv(ruta_archivo_empleados)  # Cambié el nombre de df_empleados_leido a df_empleados\n",
    "\n",
    "# 2. Leer el archivo CSV de bonificaciones\n",
    "ruta_archivo_bonificaciones = 'C:/Users/layla/Escritorio/Fundamentos de ETL con Python/Codigos y Notebooks/14. Transformaciones Avanzadas//bonificaciones.csv'\n",
    "df_bonificaciones = pd.read_csv(ruta_archivo_bonificaciones)\n",
    "\n",
    "# Mostrar los DataFrames leídos\n",
    "print(\"\\nDataset de empleados leído desde el archivo CSV:\")\n",
    "print(df_empleados)\n",
    "\n",
    "print(\"\\nDataset de bonificaciones leído desde el archivo CSV:\")\n",
    "print(df_bonificaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6262aad-913c-4e62-9b63-cc3afe5463d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset de empleados con salario anualizado:\n",
      "   ID_Empleado  Nombre Departamento  Salario Fecha_Ingreso  Salario_Anual\n",
      "0            1     Ana       Ventas    50000    2015-06-01         600000\n",
      "1            2    Luis           TI    70000    2017-03-15         840000\n",
      "2            3   Pedro    Marketing    60000    2018-11-01         720000\n",
      "3            4   Marta           TI    75000    2020-01-10         900000\n",
      "4            5  Carlos       Ventas    52000    2016-05-01         624000\n",
      "5            6   Laura    Marketing    59000    2019-07-23         708000\n",
      "6            7    José       Ventas    48000    2021-01-01         576000\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 3. Aplicación de funciones personalizadas\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Definir una función personalizada para calcular el salario anualizado\n",
    "def salario_anual(salario):\n",
    "    return salario * 12\n",
    "\n",
    "# Aplicar la función personalizada a la columna 'Salario' de df_empleados\n",
    "df_empleados['Salario_Anual'] = df_empleados['Salario'].apply(salario_anual)\n",
    "\n",
    "print(\"\\nDataset de empleados con salario anualizado:\")\n",
    "print(df_empleados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9759e8-9bbf-4917-9ad4-e8bea4fb708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset de empleados con la antigüedad mayor a 5 años:\n",
      "   ID_Empleado  Nombre Departamento  Salario Fecha_Ingreso  Salario_Anual  \\\n",
      "0            1     Ana       Ventas    50000    2015-06-01         600000   \n",
      "1            2    Luis           TI    70000    2017-03-15         840000   \n",
      "2            3   Pedro    Marketing    60000    2018-11-01         720000   \n",
      "3            4   Marta           TI    75000    2020-01-10         900000   \n",
      "4            5  Carlos       Ventas    52000    2016-05-01         624000   \n",
      "5            6   Laura    Marketing    59000    2019-07-23         708000   \n",
      "6            7    José       Ventas    48000    2021-01-01         576000   \n",
      "\n",
      "   Antiguedad_Mayor_5  \n",
      "0                True  \n",
      "1                True  \n",
      "2                True  \n",
      "3               False  \n",
      "4                True  \n",
      "5                True  \n",
      "6               False  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 4. Uso de apply() para aplicar funciones más complejas\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Crear una función que calcule si un empleado tiene más de 5 años de antigüedad\n",
    "def antiguedad_5_anos(fecha_ingreso):\n",
    "    today = pd.to_datetime('today')\n",
    "    antiguedad = today - pd.to_datetime(fecha_ingreso)\n",
    "    return antiguedad.days / 365 > 5\n",
    "\n",
    "# Aplicar la función a la columna 'Fecha_Ingreso' para crear una nueva columna 'Antiguedad_5_anos'\n",
    "df_empleados['Antiguedad_Mayor_5'] = df_empleados['Fecha_Ingreso'].apply(antiguedad_5_anos)\n",
    "\n",
    "print(\"\\nDataset de empleados con la antigüedad mayor a 5 años:\")\n",
    "print(df_empleados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f80db1-ad2c-4d74-b34a-7e59ccb81873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabla pivote del salario promedio por departamento:\n",
      "              Salario\n",
      "Departamento         \n",
      "Marketing     59500.0\n",
      "TI            72500.0\n",
      "Ventas        50000.0\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 5. Crear tablas pivote (Pivot Tables)\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Crear una tabla pivote que muestre el salario promedio por departamento\n",
    "pivot_departamento = df_empleados.pivot_table(values='Salario', index='Departamento', aggfunc='mean')\n",
    "\n",
    "print(\"\\nTabla pivote del salario promedio por departamento:\")\n",
    "print(pivot_departamento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e021abe7-a9c2-4b53-80fe-7f40323b24cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset combinado con las bonificaciones de los empleados (Merge):\n",
      "   ID_Empleado  Nombre Departamento  Salario Fecha_Ingreso  Salario_Anual  \\\n",
      "0            1     Ana       Ventas    50000    2015-06-01         600000   \n",
      "1            2    Luis           TI    70000    2017-03-15         840000   \n",
      "2            3   Pedro    Marketing    60000    2018-11-01         720000   \n",
      "3            4   Marta           TI    75000    2020-01-10         900000   \n",
      "4            5  Carlos       Ventas    52000    2016-05-01         624000   \n",
      "5            6   Laura    Marketing    59000    2019-07-23         708000   \n",
      "6            7    José       Ventas    48000    2021-01-01         576000   \n",
      "\n",
      "   Antiguedad_Mayor_5  Bonificacion  \n",
      "0                True          5000  \n",
      "1                True          8000  \n",
      "2                True          3000  \n",
      "3               False         10000  \n",
      "4                True          2500  \n",
      "5                True          4000  \n",
      "6               False          1500  \n",
      "\n",
      "Dataset combinado usando join entre empleados y departamentos:\n",
      "              ID_Empleado  Nombre  Salario Fecha_Ingreso  Salario_Anual  \\\n",
      "Departamento                                                              \n",
      "Ventas                  1     Ana    50000    2015-06-01         600000   \n",
      "TI                      2    Luis    70000    2017-03-15         840000   \n",
      "Marketing               3   Pedro    60000    2018-11-01         720000   \n",
      "TI                      4   Marta    75000    2020-01-10         900000   \n",
      "Ventas                  5  Carlos    52000    2016-05-01         624000   \n",
      "Marketing               6   Laura    59000    2019-07-23         708000   \n",
      "Ventas                  7    José    48000    2021-01-01         576000   \n",
      "\n",
      "              Antiguedad_Mayor_5  Ubicacion  \n",
      "Departamento                                 \n",
      "Ventas                      True     Madrid  \n",
      "TI                          True  Barcelona  \n",
      "Marketing                   True   Valencia  \n",
      "TI                         False  Barcelona  \n",
      "Ventas                      True     Madrid  \n",
      "Marketing                   True   Valencia  \n",
      "Ventas                     False     Madrid  \n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------\n",
    "# 6. Merge y Join para combinar DataFrames\n",
    "# ---------------------------------------------\n",
    "\n",
    "# Realizar un merge entre los dos DataFrames usando la columna 'ID_Empleado'\n",
    "df_completo = pd.merge(df_empleados, df_bonificaciones, on='ID_Empleado', how='left')\n",
    "\n",
    "print(\"\\nDataset combinado con las bonificaciones de los empleados (Merge):\")\n",
    "print(df_completo)\n",
    "\n",
    "# Ahora, vamos a realizar un 'join' con un DataFrame diferente (usando el índice)\n",
    "# Creamos un DataFrame adicional de departamentos con la información de ubicación\n",
    "data_departamentos = {\n",
    "    'Departamento': ['Ventas', 'TI', 'Marketing'],\n",
    "    'Ubicacion': ['Madrid', 'Barcelona', 'Valencia']\n",
    "}\n",
    "\n",
    "df_departamentos = pd.DataFrame(data_departamentos)\n",
    "\n",
    "# Establecer 'Departamento' como índice del DataFrame de departamentos\n",
    "df_departamentos.set_index('Departamento', inplace=True)\n",
    "\n",
    "# Realizar un join entre el DataFrame de empleados y el de departamentos usando la columna 'Departamento'\n",
    "df_join = df_empleados.set_index('Departamento').join(df_departamentos)\n",
    "\n",
    "print(\"\\nDataset combinado usando join entre empleados y departamentos:\")\n",
    "print(df_join)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3efdeb-2bf4-4552-aa11-b1e42c9adccb",
   "metadata": {},
   "source": [
    "# Ejercicio - Challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b0dc21-40ee-4a68-a0cc-81eb93367b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    " \n",
    "# Crear el DataFrame de ejemplo\n",
    "data = {\n",
    "\t'producto': ['Camisa', 'Pantalón', 'Zapatos', 'Sudadera', 'Sombrero'],\n",
    "\t'precio': [20.0, 40.0, 50.0, 60.0, 15.0],\n",
    "    'cantidad': [2, 3, 1, 2, 5]\n",
    "}\n",
    " \n",
    "df = pd.DataFrame(data)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
